{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\veronika\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: lxml>=2.3.2 in c:\\users\\veronika\\anaconda3\\lib\\site-packages (from python-docx)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx\n",
    "#!pip install --pre python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import docx\n",
    "import re\n",
    "\n",
    "def getwordsOutofMS(filename):\n",
    "    document = docx.Document(filename)\n",
    "    docText = b'\\n\\n'.join([\n",
    "    paragraph.text.encode('utf-8') for paragraph in document.paragraphs\n",
    "    ])   \n",
    "    docText = re.sub(b\"[^a-zA-Z.+3]\",b\" \", docText).decode(\"utf-8\") \n",
    "    docText = docText.lower().split()  # Go to lower case and split them apart\n",
    "    docText = list(set(docText)) \n",
    "    print ((docText))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['on', 'analyze', 'indeed', 'mining', 'obtained', 'script', 'goal', 'data', 'the', 'results', 'a', 'indeed.com.', 'cloud', 'first', 'provided', 'run', 'for', 'based', 'is', 'at', 'objectives', 'shaohua', 'trends', 'of', 'to', 'team', 'intended', 'web', 'i.e.', 'scraping', 'salary', 'project', 'website', 'be', 'this', 'info', 'audience', 'we', 'by', 'big', 'purpose', 'tbd', 'b', 'indeed.com', 'proj', 'will', 'bigdata', 'prediction', 'scientist', 'from']\n"
     ]
    }
   ],
   "source": [
    "getwordsOutofMS('Indeed Big Data Project.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "def getwordsOutofPDF(filename):\n",
    "    pdf_file = open(filename, 'rb')\n",
    "    read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "    number_of_pages = read_pdf.getNumPages()\n",
    "    page = read_pdf.getPage(0)\n",
    "    page_content = page.extractText()\n",
    "    docText =page_content.encode('utf-8')\n",
    "    docText = re.sub(b\"[^a-zA-Z.+3]\",b\" \", docText).decode(\"utf-8\") \n",
    "    docText = docText.lower().split()  # Go to lower case and split them apart\n",
    "    docText = list(set(docText)) \n",
    "    print(docText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vm', 'setup', 'fraud', 'hbase', 'friend', 'learning', 'mllib', 'datahadoop', 'a', 'cloud', 'setting', 'assignmentproject', 'processing', 'analyticshive', 'basics', 'labadvanced', 'pymk', 'python', 'ec', 'fast', 'core', 'computing', 'programming', 'detectionaws', 'case', 'text', 'rtb', 'cluster', 'and', 'learn', 'project', 'apache', 'dynamodb', 'scalable', 'time', 'owcapstone', 'presto', 'analysis', 'modeling', 'manipulation', 'pig', 'm', 'phoenix', 'interest', 'end', 'class', 'system', 'hive', 'emr', 'segmentationwordcount', 'video', 'services', 'impala', 'lab', 'meansspark', 'data', 'advertising', 'systemword', 'visualization', 'assignmentimpala', 'linux', 'scikit', 'batching', 'ingestion', 'transformations', 'part', 'engine', 'recommender', 'work', 'file', 'web', 'launch', 'pagerank', 'machine', 'pagerankspark', 'hiveuse', 'sql', 'systemspark', 'mapreduce', 'foursquare', 'graph', 'labsql', 'projects', 'demoupload', 'sentiment', 'air', 'kafka', '3', 'nosql', 'introduction', 'in', 'tutorial', 'assignments', 'api', 'amazon', 'ecosystem', 'types', 'tutorials', 'hdfs', 'paced', 'streaming', 'with', 'predictive', 'real', 'assignmentmongodb', 'wordcount', 'pipeline', 'cassandra', 'search', 'twitter', 'automated', 'tableau', 'dataframe', 'boto', 'to', 'use', 'software', 'stream', 'log', 'movielens', 'dataset', 'using', 'analytics', 'datasetuse', 'topic', 'instance', 'labs', 'spark', 'nrt', 'rdd', 'ow', 'automationspark', 'monitoringimpala', 'capstone', 'labassignment', 'pipelines', 'installation', 'session', 'redshift', 'on', 'hadoopk', 'loading', 'online', 'idf', 'sqoop', 'ii', 'regression', 'means', 'clustering', 'r', 'up', 'mongodb', 'hdp', 'tf', 'assignmentcapstone', 'recsys', 'labcassandra', 'k', 'location', 'coding', 'big', 'self', 'ml', 'working', 'recommendationspark', 'aws', 'hadoop', 'assignment', 'apimongodb', 'luigi', 'count', 'management']\n"
     ]
    }
   ],
   "source": [
    "getwordsOutofPDF('testpdf.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
